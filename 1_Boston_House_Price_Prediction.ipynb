{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qYb_CNUAn1n5"
      },
      "outputs": [],
      "source": [
        "# If load_boston does not work then download the data and use this.\n",
        "# Data : https://github.com/afnan47/sem8/blob/master/DL/1_boston_housing.csv\n",
        "import pandas as pd\n",
        "df = pd.read_csv(\"./1_boston_housing.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "4FEDjg8rsyi0"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df.loc[:, df.columns != 'MEDV']\n",
        "y = df.loc[:, df.columns == 'MEDV']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "6WoVWw-ln1n8"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "mms = MinMaxScaler()\n",
        "mms.fit(X_train)\n",
        "X_train = mms.transform(X_train)\n",
        "X_test = mms.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VL8VMy_fs3fl",
        "outputId": "7f59a11a-7be5-44f7-88b1-a2fe28bb696b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_1 (Dense)             (None, 128)               1792      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_output (Dense)        (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 10,113\n",
            "Trainable params: 10,113\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(128, input_shape=(13, ), activation='relu', name='dense_1'))\n",
        "model.add(Dense(64, activation='relu', name='dense_2'))\n",
        "model.add(Dense(1, activation='linear', name='dense_output'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7m71ooKs5of",
        "outputId": "6e68517a-7413-4e55-9de5-677cd609d4df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "11/11 [==============================] - 1s 26ms/step - loss: 581.0051 - mae: 22.2116 - val_loss: 587.9105 - val_mae: 22.2721\n",
            "Epoch 2/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 522.5759 - mae: 20.8059 - val_loss: 519.2625 - val_mae: 20.6222\n",
            "Epoch 3/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 441.8932 - mae: 18.6813 - val_loss: 419.4532 - val_mae: 17.9238\n",
            "Epoch 4/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 332.5385 - mae: 15.4051 - val_loss: 290.7978 - val_mae: 13.8939\n",
            "Epoch 5/100\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 214.4471 - mae: 11.5673 - val_loss: 177.1291 - val_mae: 9.5543\n",
            "Epoch 6/100\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 144.9370 - mae: 9.4148 - val_loss: 131.4924 - val_mae: 8.2138\n",
            "Epoch 7/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 128.7536 - mae: 8.7567 - val_loss: 118.4900 - val_mae: 7.7970\n",
            "Epoch 8/100\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 112.3315 - mae: 8.0812 - val_loss: 108.7916 - val_mae: 7.3739\n",
            "Epoch 9/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 97.1111 - mae: 7.3637 - val_loss: 100.4136 - val_mae: 6.9413\n",
            "Epoch 10/100\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 85.6998 - mae: 6.7224 - val_loss: 93.0777 - val_mae: 6.5381\n",
            "Epoch 11/100\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 75.6851 - mae: 6.2594 - val_loss: 84.0602 - val_mae: 6.2779\n",
            "Epoch 12/100\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 67.4456 - mae: 5.9272 - val_loss: 78.0905 - val_mae: 6.0522\n",
            "Epoch 13/100\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 61.5886 - mae: 5.6468 - val_loss: 73.8072 - val_mae: 5.9644\n",
            "Epoch 14/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 56.7040 - mae: 5.2886 - val_loss: 71.5545 - val_mae: 5.7437\n",
            "Epoch 15/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 53.2271 - mae: 5.0891 - val_loss: 68.2073 - val_mae: 5.7910\n",
            "Epoch 16/100\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 50.1294 - mae: 4.9829 - val_loss: 65.4311 - val_mae: 5.8290\n",
            "Epoch 17/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 47.6177 - mae: 4.8250 - val_loss: 64.0711 - val_mae: 5.6043\n",
            "Epoch 18/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 45.6108 - mae: 4.6527 - val_loss: 62.1802 - val_mae: 5.5234\n",
            "Epoch 19/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 43.5183 - mae: 4.5837 - val_loss: 59.6807 - val_mae: 5.5380\n",
            "Epoch 20/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 41.5258 - mae: 4.4556 - val_loss: 58.9315 - val_mae: 5.2632\n",
            "Epoch 21/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 39.4293 - mae: 4.3198 - val_loss: 55.8900 - val_mae: 5.3136\n",
            "Epoch 22/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 37.4090 - mae: 4.2487 - val_loss: 53.9427 - val_mae: 5.1895\n",
            "Epoch 23/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 35.5897 - mae: 4.1420 - val_loss: 51.4710 - val_mae: 5.1166\n",
            "Epoch 24/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 33.6432 - mae: 4.0656 - val_loss: 49.9373 - val_mae: 4.9383\n",
            "Epoch 25/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 31.8741 - mae: 3.8322 - val_loss: 48.9089 - val_mae: 4.8324\n",
            "Epoch 26/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 30.1120 - mae: 3.7935 - val_loss: 45.8910 - val_mae: 4.7998\n",
            "Epoch 27/100\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 28.4556 - mae: 3.6877 - val_loss: 45.3609 - val_mae: 4.7619\n",
            "Epoch 28/100\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 26.9682 - mae: 3.5399 - val_loss: 43.7181 - val_mae: 4.7236\n",
            "Epoch 29/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 25.7215 - mae: 3.5196 - val_loss: 41.3237 - val_mae: 4.6962\n",
            "Epoch 30/100\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 25.0051 - mae: 3.3667 - val_loss: 41.7896 - val_mae: 4.6343\n",
            "Epoch 31/100\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 23.6967 - mae: 3.3888 - val_loss: 38.2446 - val_mae: 4.6164\n",
            "Epoch 32/100\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 22.5992 - mae: 3.2141 - val_loss: 40.8896 - val_mae: 4.5295\n",
            "Epoch 33/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 21.8304 - mae: 3.1850 - val_loss: 36.8671 - val_mae: 4.5388\n",
            "Epoch 34/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 20.9361 - mae: 3.1593 - val_loss: 38.9456 - val_mae: 4.4648\n",
            "Epoch 35/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 20.7198 - mae: 3.0607 - val_loss: 36.6320 - val_mae: 4.4274\n",
            "Epoch 36/100\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 20.0004 - mae: 3.0534 - val_loss: 35.8529 - val_mae: 4.3899\n",
            "Epoch 37/100\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 19.4221 - mae: 3.0162 - val_loss: 37.1665 - val_mae: 4.3190\n",
            "Epoch 38/100\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 19.2511 - mae: 2.9800 - val_loss: 35.2389 - val_mae: 4.2917\n",
            "Epoch 39/100\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 18.7737 - mae: 2.9308 - val_loss: 36.1940 - val_mae: 4.2468\n",
            "Epoch 40/100\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 18.5477 - mae: 2.9396 - val_loss: 34.5338 - val_mae: 4.2067\n",
            "Epoch 41/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 18.3648 - mae: 2.9211 - val_loss: 34.7029 - val_mae: 4.1564\n",
            "Epoch 42/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 17.9660 - mae: 2.9101 - val_loss: 33.4614 - val_mae: 4.1040\n",
            "Epoch 43/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 17.8362 - mae: 2.8768 - val_loss: 33.9550 - val_mae: 4.0611\n",
            "Epoch 44/100\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 17.7445 - mae: 2.8543 - val_loss: 32.7457 - val_mae: 4.0091\n",
            "Epoch 45/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 17.7013 - mae: 2.9220 - val_loss: 33.5902 - val_mae: 4.0083\n",
            "Epoch 46/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 17.3716 - mae: 2.8302 - val_loss: 33.7282 - val_mae: 3.9888\n",
            "Epoch 47/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 17.3450 - mae: 2.8836 - val_loss: 31.7057 - val_mae: 3.9186\n",
            "Epoch 48/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 16.9977 - mae: 2.7855 - val_loss: 33.0867 - val_mae: 3.9186\n",
            "Epoch 49/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 16.8227 - mae: 2.7771 - val_loss: 30.8433 - val_mae: 3.8434\n",
            "Epoch 50/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 16.6337 - mae: 2.8007 - val_loss: 31.1348 - val_mae: 3.8272\n",
            "Epoch 51/100\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 16.4104 - mae: 2.7480 - val_loss: 30.8593 - val_mae: 3.7760\n",
            "Epoch 52/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 16.3071 - mae: 2.7711 - val_loss: 29.5809 - val_mae: 3.7188\n",
            "Epoch 53/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 16.1833 - mae: 2.7483 - val_loss: 31.2305 - val_mae: 3.7512\n",
            "Epoch 54/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 16.0771 - mae: 2.7185 - val_loss: 29.4290 - val_mae: 3.6498\n",
            "Epoch 55/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 15.9034 - mae: 2.7376 - val_loss: 29.2556 - val_mae: 3.6102\n",
            "Epoch 56/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 15.9851 - mae: 2.6915 - val_loss: 29.3986 - val_mae: 3.5953\n",
            "Epoch 57/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 15.7196 - mae: 2.7194 - val_loss: 29.3213 - val_mae: 3.5859\n",
            "Epoch 58/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 15.8658 - mae: 2.6772 - val_loss: 28.3416 - val_mae: 3.5163\n",
            "Epoch 59/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 15.6671 - mae: 2.7361 - val_loss: 28.3080 - val_mae: 3.4982\n",
            "Epoch 60/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 15.2547 - mae: 2.6392 - val_loss: 28.1446 - val_mae: 3.4774\n",
            "Epoch 61/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 15.2781 - mae: 2.6303 - val_loss: 27.6798 - val_mae: 3.4503\n",
            "Epoch 62/100\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 15.3550 - mae: 2.6813 - val_loss: 29.2800 - val_mae: 3.5080\n",
            "Epoch 63/100\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 15.1406 - mae: 2.6692 - val_loss: 27.1907 - val_mae: 3.4025\n",
            "Epoch 64/100\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 15.1299 - mae: 2.6099 - val_loss: 27.7813 - val_mae: 3.4020\n",
            "Epoch 65/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 14.7736 - mae: 2.6146 - val_loss: 26.7004 - val_mae: 3.3364\n",
            "Epoch 66/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 14.9309 - mae: 2.5722 - val_loss: 26.9384 - val_mae: 3.3208\n",
            "Epoch 67/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 14.6225 - mae: 2.6311 - val_loss: 26.0748 - val_mae: 3.2685\n",
            "Epoch 68/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 14.4384 - mae: 2.5658 - val_loss: 27.1026 - val_mae: 3.3072\n",
            "Epoch 69/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 14.4938 - mae: 2.5853 - val_loss: 26.9711 - val_mae: 3.2817\n",
            "Epoch 70/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 14.4893 - mae: 2.5429 - val_loss: 24.5520 - val_mae: 3.1797\n",
            "Epoch 71/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 14.3073 - mae: 2.6144 - val_loss: 26.6924 - val_mae: 3.2305\n",
            "Epoch 72/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 14.5643 - mae: 2.5330 - val_loss: 24.9575 - val_mae: 3.1850\n",
            "Epoch 73/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 14.1716 - mae: 2.5751 - val_loss: 26.4007 - val_mae: 3.2201\n",
            "Epoch 74/100\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 13.9970 - mae: 2.5085 - val_loss: 25.4687 - val_mae: 3.1596\n",
            "Epoch 75/100\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 13.8692 - mae: 2.5188 - val_loss: 24.1895 - val_mae: 3.1158\n",
            "Epoch 76/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 13.8778 - mae: 2.5143 - val_loss: 24.4412 - val_mae: 3.0879\n",
            "Epoch 77/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 13.7491 - mae: 2.4982 - val_loss: 24.1284 - val_mae: 3.0547\n",
            "Epoch 78/100\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 13.7613 - mae: 2.5242 - val_loss: 23.8715 - val_mae: 3.0401\n",
            "Epoch 79/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 13.6631 - mae: 2.4850 - val_loss: 23.6357 - val_mae: 3.0219\n",
            "Epoch 80/100\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 13.5100 - mae: 2.4896 - val_loss: 23.5406 - val_mae: 3.0174\n",
            "Epoch 81/100\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 13.6057 - mae: 2.4630 - val_loss: 23.6754 - val_mae: 3.0242\n",
            "Epoch 82/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 13.4197 - mae: 2.4980 - val_loss: 23.5251 - val_mae: 2.9814\n",
            "Epoch 83/100\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 13.3658 - mae: 2.4621 - val_loss: 23.8067 - val_mae: 2.9712\n",
            "Epoch 84/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 13.3079 - mae: 2.4538 - val_loss: 22.5946 - val_mae: 2.9453\n",
            "Epoch 85/100\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 13.1803 - mae: 2.4598 - val_loss: 23.6877 - val_mae: 2.9830\n",
            "Epoch 86/100\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 13.1615 - mae: 2.4288 - val_loss: 22.2061 - val_mae: 2.9193\n",
            "Epoch 87/100\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 13.1206 - mae: 2.4676 - val_loss: 23.0082 - val_mae: 2.9356\n",
            "Epoch 88/100\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 12.9750 - mae: 2.4385 - val_loss: 22.5221 - val_mae: 2.9116\n",
            "Epoch 89/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 12.9221 - mae: 2.4229 - val_loss: 22.1954 - val_mae: 2.8912\n",
            "Epoch 90/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 13.1197 - mae: 2.4080 - val_loss: 20.4513 - val_mae: 2.8580\n",
            "Epoch 91/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 13.0697 - mae: 2.5126 - val_loss: 24.3091 - val_mae: 3.0395\n",
            "Epoch 92/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 13.1693 - mae: 2.3977 - val_loss: 19.9624 - val_mae: 2.8284\n",
            "Epoch 93/100\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 12.9481 - mae: 2.4838 - val_loss: 23.7128 - val_mae: 3.0036\n",
            "Epoch 94/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 12.7018 - mae: 2.4091 - val_loss: 20.0264 - val_mae: 2.8159\n",
            "Epoch 95/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 12.5954 - mae: 2.4110 - val_loss: 21.5556 - val_mae: 2.8280\n",
            "Epoch 96/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 12.5513 - mae: 2.3723 - val_loss: 19.6175 - val_mae: 2.7545\n",
            "Epoch 97/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 12.5316 - mae: 2.3678 - val_loss: 20.3706 - val_mae: 2.7411\n",
            "Epoch 98/100\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 12.4351 - mae: 2.3778 - val_loss: 19.6587 - val_mae: 2.7010\n",
            "Epoch 99/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 12.3038 - mae: 2.4124 - val_loss: 20.1783 - val_mae: 2.7354\n",
            "Epoch 100/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 12.3769 - mae: 2.3592 - val_loss: 18.9471 - val_mae: 2.7240\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(X_train, y_train, epochs=100, validation_split=0.05, verbose = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzY8zjL5s9jS",
        "outputId": "7c302b7b-6506-4ce7-b756-17d1edd49bcd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 2ms/step - loss: 22.0485 - mae: 3.0463\n",
            "Mean squared error on test data:  22.048465728759766\n",
            "Mean absolute error on test data:  3.0463273525238037\n"
          ]
        }
      ],
      "source": [
        "mse_nn, mae_nn = model.evaluate(X_test, y_test)\n",
        "\n",
        "print('Mean squared error on test data: ', mse_nn)\n",
        "print('Mean absolute error on test data: ', mae_nn)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}